{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "MG-Z23g6enI4",
    "outputId": "1fe91fa2-5bc0-43ef-dbc0-8b828d39322b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "l5eAQQOte-JJ",
    "outputId": "a76842e6-d516-4f2c-b186-6421622c8a4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "aOa-aSGBfIdA",
    "outputId": "34f4faf2-94ca-47c3-ce57-56ae6e00f445"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>24h</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>1</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid reflection_period  ... num_sentence  predicted_category\n",
       "0  27673               24h  ...            1           affection\n",
       "1  27674               24h  ...            1           affection\n",
       "2  27675               24h  ...            1            exercise\n",
       "3  27676               24h  ...            2             bonding\n",
       "4  27677               24h  ...            1           affection\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('gdrive/My Drive/Colab Notebooks/hm_train.csv') # Reading the csv file from google drive folder\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "colab_type": "code",
    "id": "Wya9NOhuEb2P",
    "outputId": "7e7e11ea-e17f-455c-ce6d-eec436508d4a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"popular\")\n",
    "stopwords = nltk.corpus.stopwords.words('english') # Has all the stopwords in english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n5NzuBeWEJPJ"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # It first checks for the punctuation characters and removes it. Next it converts the char to lowercase and joins the chars to form words.\n",
    "    text = ''.join([word.lower() for word in text if word not in string.punctuation])\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords)\n",
    "    # This \\W+ regex, indicates that it will split wherever it sees one or more non-word characters.\n",
    "    tokens = re.split('\\W+',text)\n",
    "    # removing stopwords and stemming at a time\n",
    "    #text = [word for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "GBE7arCWEJMH",
    "outputId": "5b99ada8-9835-4dcf-d179-9cfee418e7db",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>went successful date someone felt sympathy con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>24h</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>happy son got 90 marks examination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>1</td>\n",
       "      <td>exercise</td>\n",
       "      <td>went gym morning yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>serious talk friends flaky lately understood g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>went grandchildren butterfly display crohn con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid  ...                                       cleaned_text\n",
       "0  27673  ...  went successful date someone felt sympathy con...\n",
       "1  27674  ...                 happy son got 90 marks examination\n",
       "2  27675  ...                              went gym morning yoga\n",
       "3  27676  ...  serious talk friends flaky lately understood g...\n",
       "4  27677  ...  went grandchildren butterfly display crohn con...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying the clean_text function to the cleaned_hm column\n",
    "df['cleaned_text'] = df.cleaned_hm.apply(lambda x: clean_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tokenize and find out unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WlhJhkKt6uVG",
    "outputId": "46501cc0-75b7-4907-ec1c-929f8c11fbcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23001 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each row(cleaned_hm).\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['cleaned_text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convert text to sequences and padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OzOs63RGFOT-",
    "outputId": "b2535fc2-5c0f-4f99-c3c2-f39fe7b64828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (60321, 250)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['cleaned_text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "id": "drC3xbZu6oAQ",
    "outputId": "93e8605a-8020-4390-9797-c721eecf4dc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,  394, 4160, 5382,   77,   86], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[8888]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "I4UEziqdhhi2",
    "outputId": "090a2c9b-101e-4ec8-bdbb-4aca611b2d2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (60321, 7)\n"
     ]
    }
   ],
   "source": [
    "y = pd.get_dummies(df['predicted_category']).values # One hot encoding for the Y variable\n",
    "print('Shape of label tensor:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Split the data into train & test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "i82pASwUh2Jo",
    "outputId": "cade8c2a-fa01-41c5-a0bb-97665817b699",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54288, 250) (54288, 7)\n",
      "(6033, 250) (6033, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10,random_state=42)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Build a sequencial model and complie it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "QUvbTrzSi0LI",
    "outputId": "96217038-33a3-438f-9c0f-8a91b06fcb2a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 5,081,107\n",
      "Trainable params: 5,081,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Fit the model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "q7gF5MG1mxxv",
    "outputId": "0cf261e6-40d0-4a7d-bde3-71e6cc29753a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48859 samples, validate on 5429 samples\n",
      "Epoch 1/5\n",
      "48859/48859 [==============================] - 425s 9ms/step - loss: 0.6906 - acc: 0.7617 - val_loss: 0.3566 - val_acc: 0.8786\n",
      "Epoch 2/5\n",
      "48859/48859 [==============================] - 423s 9ms/step - loss: 0.2659 - acc: 0.9088 - val_loss: 0.3010 - val_acc: 0.8904\n",
      "Epoch 3/5\n",
      "48859/48859 [==============================] - 422s 9ms/step - loss: 0.1700 - acc: 0.9411 - val_loss: 0.3074 - val_acc: 0.8959\n",
      "Epoch 4/5\n",
      "48859/48859 [==============================] - 425s 9ms/step - loss: 0.1251 - acc: 0.9563 - val_loss: 0.3268 - val_acc: 0.8945\n",
      "Epoch 5/5\n",
      "48859/48859 [==============================] - 426s 9ms/step - loss: 0.0998 - acc: 0.9656 - val_loss: 0.3445 - val_acc: 0.8928\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "5o-lBaw8nIy3",
    "outputId": "bc8336b2-9bbd-4e44-f0aa-5f15b9cdfe5e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6033/6033 [==============================] - 36s 6ms/step\n",
      "Test set\n",
      "  Loss: 0.389\n",
      "  Accuracy: 0.887\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Category of Happiness on Unseen data(hm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WfSM8fnronUK"
   },
   "outputs": [],
   "source": [
    "df_test =pd.read_csv('gdrive/My Drive/Colab Notebooks/hm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "LH4LBv_T5813",
    "outputId": "0891f924-9e70-4178-ffa7-ebfa0242c729"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>num_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88305</td>\n",
       "      <td>3m</td>\n",
       "      <td>I spent the weekend in Chicago with my friends.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88306</td>\n",
       "      <td>3m</td>\n",
       "      <td>We moved back into our house after a remodel. ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88307</td>\n",
       "      <td>3m</td>\n",
       "      <td>My fiance proposed to me in front of my family...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88308</td>\n",
       "      <td>3m</td>\n",
       "      <td>I ate lobster at a fancy restaurant with some ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88309</td>\n",
       "      <td>3m</td>\n",
       "      <td>I went out to a nice restaurant on a date with...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid  ... num_sentence\n",
       "0  88305  ...            1\n",
       "1  88306  ...            2\n",
       "2  88307  ...            1\n",
       "3  88308  ...            1\n",
       "4  88309  ...            5\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "nZAszS905_Pu",
    "outputId": "bd68733d-3e81-423c-977b-885c3c56d42f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88305</td>\n",
       "      <td>3m</td>\n",
       "      <td>I spent the weekend in Chicago with my friends.</td>\n",
       "      <td>1</td>\n",
       "      <td>spent weekend chicago friends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88306</td>\n",
       "      <td>3m</td>\n",
       "      <td>We moved back into our house after a remodel. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>moved back house remodel lived hotel 9 months ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88307</td>\n",
       "      <td>3m</td>\n",
       "      <td>My fiance proposed to me in front of my family...</td>\n",
       "      <td>1</td>\n",
       "      <td>fiance proposed front family beginning march</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88308</td>\n",
       "      <td>3m</td>\n",
       "      <td>I ate lobster at a fancy restaurant with some ...</td>\n",
       "      <td>1</td>\n",
       "      <td>ate lobster fancy restaurant friends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88309</td>\n",
       "      <td>3m</td>\n",
       "      <td>I went out to a nice restaurant on a date with...</td>\n",
       "      <td>5</td>\n",
       "      <td>went nice restaurant date wife popular restaur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid  ...                                       cleaned_text\n",
       "0  88305  ...                      spent weekend chicago friends\n",
       "1  88306  ...  moved back house remodel lived hotel 9 months ...\n",
       "2  88307  ...       fiance proposed front family beginning march\n",
       "3  88308  ...               ate lobster fancy restaurant friends\n",
       "4  88309  ...  went nice restaurant date wife popular restaur...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying the clean_text function to the cleaned_hm column\n",
    "df_test['cleaned_text'] = df_test.cleaned_hm.apply(lambda x: clean_text(x))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0Fgr-6Dy6KJl",
    "outputId": "d5a96146-3034-49e9-a284-a139a5fbfdab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18460 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each row(cleaned_hm).\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df_test['cleaned_text'])\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9_sT3jPN6b1W",
    "outputId": "59b8c6f5-efca-4e51-ccbd-2fe924ad887f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (40213, 250)\n"
     ]
    }
   ],
   "source": [
    "X_new = tokenizer.texts_to_sequences(df_test['cleaned_text'].values)\n",
    "X_new = pad_sequences(X_new, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kUExzfQb7AIE"
   },
   "outputs": [],
   "source": [
    "labels = ['achievement', 'affection', 'bonding', 'enjoy_the_moment', 'exercise',\n",
    "       'leisure', 'nature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uSKN02XDip-w"
   },
   "outputs": [],
   "source": [
    "X_DF = pd.DataFrame(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "VkHy-n_vkf7j",
    "outputId": "2f2f23a1-03f2-4ebe-8b1b-7492fe50f6ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>96</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    ...  243  244  245  246  247   248  249\n",
       "0    0    0    0    0    0    0    0  ...    0    0    0  113   96  2020   16\n",
       "\n",
       "[1 rows x 250 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_DF.iloc[:2] # checking the input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4KytRSFg7KLj"
   },
   "outputs": [],
   "source": [
    "pred_new_data = model.predict(X_DF) # predicting for the whole data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "fBMz8wFvnR45",
    "outputId": "683ebdd1-b90d-4475-858b-83c30485a830"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.998818</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>3.170371e-06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>2.411445e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991206</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>1.134637e-04</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>1.602407e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.990685</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.006183</td>\n",
       "      <td>1.142284e-04</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>3.858813e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.261579e-07</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2.066169e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.165953</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>4.592930e-04</td>\n",
       "      <td>0.824954</td>\n",
       "      <td>2.064804e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40208</th>\n",
       "      <td>0.032383</td>\n",
       "      <td>0.095041</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>0.730514</td>\n",
       "      <td>1.369833e-02</td>\n",
       "      <td>0.109740</td>\n",
       "      <td>6.499065e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40209</th>\n",
       "      <td>0.742372</td>\n",
       "      <td>0.120104</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>0.023164</td>\n",
       "      <td>6.912437e-02</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>1.832702e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40210</th>\n",
       "      <td>0.011982</td>\n",
       "      <td>0.983128</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>3.478006e-04</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>5.283003e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40211</th>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>4.707286e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.054863e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40212</th>\n",
       "      <td>0.089061</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.007637</td>\n",
       "      <td>0.015249</td>\n",
       "      <td>1.697291e-02</td>\n",
       "      <td>0.863724</td>\n",
       "      <td>6.078030e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40213 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2  ...             4         5             6\n",
       "0      0.000864  0.998818  0.000018  ...  3.170371e-06  0.000018  2.411445e-06\n",
       "1      0.991206  0.000349  0.002237  ...  1.134637e-04  0.000204  1.602407e-04\n",
       "2      0.990685  0.000822  0.001600  ...  1.142284e-04  0.000211  3.858813e-04\n",
       "3      0.000036  0.999946  0.000003  ...  1.261579e-07  0.000011  2.066169e-07\n",
       "4      0.165953  0.001465  0.005591  ...  4.592930e-04  0.824954  2.064804e-04\n",
       "...         ...       ...       ...  ...           ...       ...           ...\n",
       "40208  0.032383  0.095041  0.012125  ...  1.369833e-02  0.109740  6.499065e-03\n",
       "40209  0.742372  0.120104  0.019097  ...  6.912437e-02  0.007811  1.832702e-02\n",
       "40210  0.011982  0.983128  0.002688  ...  3.478006e-04  0.000284  5.283003e-04\n",
       "40211  0.999856  0.000021  0.000052  ...  4.707286e-06  0.000002  2.054863e-06\n",
       "40212  0.089061  0.001278  0.007637  ...  1.697291e-02  0.863724  6.078030e-03\n",
       "\n",
       "[40213 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred_new_data) #probabilities for all the classes, 7 columns are nothing but classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ln9j1XbC7ZMo",
    "outputId": "7fd9defe-0821-459f-cf55-f4828bd5c46e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40213"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iEGWi6Nu8ZKL"
   },
   "outputs": [],
   "source": [
    "# Creating a list to store the classes for each sentence\n",
    "predicted_category = []\n",
    "# Looping through the array sentences one by one to find out the maximum probability class and append it to the predicted_category variable \n",
    "for i in range(len(pred_new_data)):\n",
    "    p = labels[np.argmax(pred_new_data[i])]\n",
    "    predicted_category.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGFo3wxZ8ga6"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'hmid':df_test.hmid,'predicted_category':predicted_category})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "CylxZM3J8kwD",
    "outputId": "75014b37-f841-4240-ab44-4b6dcf32dd4b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88305</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88306</td>\n",
       "      <td>achievement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88307</td>\n",
       "      <td>achievement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88308</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88309</td>\n",
       "      <td>leisure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid predicted_category\n",
       "0  88305          affection\n",
       "1  88306        achievement\n",
       "2  88307        achievement\n",
       "3  88308          affection\n",
       "4  88309            leisure"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "h0xdwWpC8nDG",
    "outputId": "1348d892-1618-44e7-ae7d-3a59da42c398"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "achievement         15300\n",
       "affection           12731\n",
       "enjoy_the_moment     4739\n",
       "bonding              4645\n",
       "leisure              2341\n",
       "nature                264\n",
       "exercise              193\n",
       "Name: predicted_category, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.predicted_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By using LSTM as the neurons for the hidden layers, I built the deep neural network model and got 88.7% accuracy on the test data.The LinearSVC model is performing better than the LSTMs model on the test data. So, the best model to predict the happiness source is LinearSVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ByUsing_Keras_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
